{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "a = np.zeros(25)\n",
    "b = a.reshape(5,5)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0., 0., 0.],\n       [0., 1., 2., 0., 0.],\n       [0., 2., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "b[2,2]=1\n",
    "b[1,1]=1\n",
    "b[3,3]=1\n",
    "b[2,1]=2\n",
    "b[1,2]=2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 2.],\n        [0., 0., 0., 0., 0.]]])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "c = np.zeros(3*5*5)\n",
    "c = c.reshape(3,5,5)\n",
    "c[2,3,4] = 2\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([2], dtype=int64), array([3], dtype=int64), array([4], dtype=int64))"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "y = np.where(c == 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0., 10.],\n        [ 0.,  0.,  0.,  0.,  0.]]])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "c[y] = 10\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_augment.py\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "# from PIL import Image\n",
    "\n",
    "\n",
    "# 椒盐噪声（输入图像，噪声个数）\n",
    "def salt(img, n):\n",
    "    for k in range(n):\n",
    "        i = int(np.random.random() * img.shape[1])\n",
    "        j = int(np.random.random() * img.shape[0])\n",
    "        if img.ndim == 2:\n",
    "            img[j, i] = 255\n",
    "        elif img.ndim == 3:\n",
    "            img[j, i, 0] = 255\n",
    "            img[j, i, 1] = 255\n",
    "            img[j, i, 2] = 255\n",
    "    return img\n",
    "\n",
    "# 椒盐噪声\n",
    "def SaltAndPepper(src,percetage):\n",
    "    SP_NoiseImg=src.copy()\n",
    "    SP_NoiseNum=int(percetage*src.shape[0]*src.shape[1])\n",
    "    for i in range(SP_NoiseNum):\n",
    "        randR=np.random.randint(0,src.shape[0]-1)\n",
    "        randG=np.random.randint(0,src.shape[1]-1)\n",
    "        randB=np.random.randint(0,3)\n",
    "        if np.random.randint(0,1)==0:\n",
    "            SP_NoiseImg[randR,randG,randB]=0\n",
    "        else:\n",
    "            SP_NoiseImg[randR,randG,randB]=255\n",
    "    return SP_NoiseImg\n",
    "\n",
    "# 高斯噪声\n",
    "def addGaussianNoise(image,percetage):\n",
    "    G_Noiseimg = image.copy()\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    G_NoiseNum=int(percetage*image.shape[0]*image.shape[1])\n",
    "    for i in range(G_NoiseNum):\n",
    "        temp_x = np.random.randint(0,h)\n",
    "        temp_y = np.random.randint(0,w)\n",
    "        G_Noiseimg[temp_x][temp_y][np.random.randint(3)] = np.random.randn(1)[0]\n",
    "    return G_Noiseimg\n",
    "\n",
    "# 昏暗\n",
    "def darker(image,percetage=0.8):\n",
    "    image_copy = image.copy()\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    #get darker\n",
    "    for xi in range(0,w):\n",
    "        for xj in range(0,h):\n",
    "            image_copy[xj,xi,0] = int(image[xj,xi,0]*percetage)\n",
    "            image_copy[xj,xi,1] = int(image[xj,xi,1]*percetage)\n",
    "            image_copy[xj,xi,2] = int(image[xj,xi,2]*percetage)\n",
    "    return image_copy\n",
    "\n",
    "# 亮度\n",
    "def brighter(image, percetage=1.4):\n",
    "    image_copy = image.copy()\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    #get brighter\n",
    "    for xi in range(0,w):\n",
    "        for xj in range(0,h):\n",
    "            image_copy[xj,xi,0] = np.clip(int(image[xj,xi,0]*percetage),a_max=255,a_min=0)\n",
    "            image_copy[xj,xi,1] = np.clip(int(image[xj,xi,1]*percetage),a_max=255,a_min=0)\n",
    "            image_copy[xj,xi,2] = np.clip(int(image[xj,xi,2]*percetage),a_max=255,a_min=0)\n",
    "    return image_copy\n",
    "\n",
    "# 旋转\n",
    "def rotate(image, angle, center=None, scale=1.0):\n",
    "    (h, w) = image.shape[:2]\n",
    "    # If no rotation center is specified, the center of the image is set as the rotation center\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "    m = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, m, (w, h))\n",
    "    return rotated\n",
    "\n",
    "# 翻转\n",
    "def flip(image):\n",
    "    flipped_image = np.fliplr(image)\n",
    "    return flipped_image\n",
    "\n",
    "class AUGMENT_data():\n",
    "    def __init__(self, data_path):\n",
    "        # 初始化函数，读取所有data_path下的图片\n",
    "        self.data_path = data_path\n",
    "        self.imgs_paths = glob.glob(os.path.join(data_path, 'imgs/*.jpg'))\n",
    "        self.image_bright = 0\n",
    "        self.image_path = ''\n",
    "        self.label_path = ''\n",
    "    \n",
    "    def augment_img(self, img, lab):\n",
    "        image = img\n",
    "        label = lab\n",
    "        # print(self.image_bright)\n",
    "        #变亮、变暗\n",
    "        if self.image_bright > 180:\n",
    "            img_b = darker(image)\n",
    "            save_imgres_path = self.image_path.split('.')[0] + '_darker.jpg'\n",
    "            save_labelres_path = self.label_path.split('.')[0] + '_darker.png'\n",
    "            cv2.imwrite(save_imgres_path, img_b)\n",
    "            cv2.imwrite(save_labelres_path, label)\n",
    "        elif self.image_bright < 100:\n",
    "            img_b = brighter(image)\n",
    "            save_imgres_path = self.image_path.split('.')[0] + '_bright.jpg'\n",
    "            save_labelres_path = self.label_path.split('.')[0] + '_bright.png'\n",
    "            cv2.imwrite(save_imgres_path, img_b)\n",
    "            cv2.imwrite(save_labelres_path, label)\n",
    "\n",
    "        # 旋转\n",
    "        rotated_90 = rotate(image, 90)\n",
    "        rotated_90_label = rotate(label, 90)\n",
    "        save_imgres_path = self.image_path.split('.')[0] + '_rotated_90.jpg'\n",
    "        save_labelres_path = self.label_path.split('.')[0] + '_rotated_90.png'\n",
    "        cv2.imwrite(save_imgres_path, rotated_90)\n",
    "        cv2.imwrite(save_labelres_path, rotated_90_label)\n",
    "\n",
    "        rotated_180 = rotate(image, 180)\n",
    "        rotated_180_label = rotate(label, 180)\n",
    "        save_imgres_path = self.image_path.split('.')[0] + '_rotated_180.jpg'\n",
    "        save_labelres_path = self.label_path.split('.')[0] + '_rotated_180.png'\n",
    "        cv2.imwrite(save_imgres_path, rotated_180)\n",
    "        cv2.imwrite(save_labelres_path, rotated_180_label)\n",
    "\n",
    "        # 镜像\n",
    "        flipCode = random.choice([-1, 0, 1])\n",
    "        flipped_img = cv2.flip(image, flipCode)\n",
    "        flipped_label = cv2.flip(label, flipCode)\n",
    "        save_imgres_path = self.image_path.split('.')[0] + '_flipped.jpg'\n",
    "        save_labelres_path = self.label_path.split('.')[0] + '_flipped.png'\n",
    "        cv2.imwrite(save_imgres_path, flipped_img)\n",
    "        cv2.imwrite(save_labelres_path, flipped_label)\n",
    "\n",
    "        # 增加噪声\n",
    "        img_salt = SaltAndPepper(img, 0.2)\n",
    "        save_imgres_path = self.image_path.split('.')[0] + '_salt.jpg'\n",
    "        save_labelres_path = self.label_path.split('.')[0] + '_salt.png'\n",
    "        cv2.imwrite(save_imgres_path, img_salt)\n",
    "        cv2.imwrite(save_labelres_path, label)\n",
    "\n",
    "        img_gauss = addGaussianNoise(img, 0.2)\n",
    "        save_imgres_path = self.image_path.split('.')[0] + '_gauss.jpg'\n",
    "        save_labelres_path = self.label_path.split('.')[0] + '_gauss.png'\n",
    "        cv2.imwrite(save_imgres_path, img_gauss)\n",
    "        cv2.imwrite(save_labelres_path, label)\n",
    "\n",
    "    def getitem(self):\n",
    "        for image_path in self.imgs_paths:\n",
    "            # 根据image_path生成label_path\n",
    "            label_path = image_path.replace('imgs', 'masks')\n",
    "            label_path = label_path.replace('jpg', 'png')\n",
    "            self.image_path = image_path\n",
    "            self.label_path = label_path\n",
    "            # 读取训练图片和标签图片\n",
    "            image = cv2.imread(image_path)\n",
    "            label = cv2.imread(label_path)\n",
    "            self.image_bright = image.mean()\n",
    "            print(image.shape)\n",
    "            # print(image.mean())\n",
    "            # print(type(image))\n",
    "            # print(image.max())\n",
    "            # print(image.min())\n",
    "            print(label.shape)\n",
    "            # 进行数据增广，并保存\n",
    "            image = self.augment_img(image, label)\n",
    "            print('saved ********')\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回训练集大小\n",
    "        return len(self.imgs_paths)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    augment_data = AUGMENT_data(\"data_augment/\")\n",
    "    print(\"数据个数：\", len(augment_data))\n",
    "    augment_data.getitem()\n",
    "    print('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像的亮度、对比度、色度和锐度四种方式的增强（或减弱）处理\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "# 原始图像\n",
    "def ImageAugument():\n",
    "    path = r'C:\\\\Users\\\\hkc\\\\Desktop\\\\meter_img\\\\temporary_test'  # 文件夹目录\n",
    "    files = os.listdir(path)  # 得到文件夹下的所有文件名称\n",
    "    # 遍历文件夹\n",
    "    prefix = path + '/'\n",
    "    for file in files:\n",
    "        # print(file)\n",
    "        image = Image.open(prefix + file)\n",
    "        # image.show()\n",
    "\n",
    "        # 亮度增强\n",
    "        enh_bri = ImageEnhance.Brightness(image)\n",
    "        brightness = 1.5\n",
    "        image_brightened = enh_bri.enhance(brightness)\n",
    "        image_brightened.save(prefix + file.strip('.jpg') + '-lightup' + '.jpg')\n",
    "        # 亮度减弱\n",
    "        enh_bri = ImageEnhance.Brightness(image)\n",
    "        brightness = 0.5\n",
    "        image_brightened = enh_bri.enhance(brightness)\n",
    "        image_brightened.save(prefix + file.strip('.jpg') + '-lightdown' + '.jpg')\n",
    "\n",
    "        # 色度增强\n",
    "        enh_col = ImageEnhance.Color(image)\n",
    "        color = 1.5\n",
    "        image_colored = enh_col.enhance(color)\n",
    "        image_colored.save(prefix + file.strip('.jpg') + '-colorup' + '.jpg')\n",
    "        # 色度减弱\n",
    "        enh_col = ImageEnhance.Color(image)\n",
    "        color = 0.5\n",
    "        image_colored = enh_col.enhance(color)\n",
    "        image_colored.save(prefix + file.strip('.jpg') + '-colordown' + '.jpg')\n",
    "\n",
    "        # 对比度增强\n",
    "        enh_con = ImageEnhance.Contrast(image)\n",
    "        contrast = 1.7\n",
    "        image_contrasted = enh_con.enhance(contrast)\n",
    "        image_contrasted.save(prefix + file.strip('.jpg') + '-contrastup' + '.jpg')\n",
    "        # 对比度减弱\n",
    "        enh_con = ImageEnhance.Contrast(image)\n",
    "        contrast = 0.7\n",
    "        image_contrasted = enh_con.enhance(contrast)\n",
    "        image_contrasted.save(prefix + file.strip('.jpg') + '-contrastdown' + '.jpg')\n",
    "\n",
    "        # # 锐度增强\n",
    "        # enh_sha = ImageEnhance.Sharpness(image)\n",
    "        # sharpness = 3.0\n",
    "        # image_sharped = enh_sha.enhance(sharpness)\n",
    "        # image_sharped.save(prefix + file.strip('.jpg') + '-moreSharup' + '.jpg')\n",
    "        # # 锐度减弱\n",
    "        # enh_sha = ImageEnhance.Sharpness(image)\n",
    "        # sharpness = 1.5\n",
    "        # image_sharped = enh_sha.enhance(sharpness)\n",
    "        # image_sharped.save(prefix + file.strip('.jpg') + '-moreShardown' + '.jpg')\n",
    "\n",
    "        # 椒盐噪声\n",
    "        SP_NoiseImg = image.copy()\n",
    "        pim = SP_NoiseImg.load()\n",
    "        percetage = 0.1\n",
    "        SP_NoiseNum=int(percetage*image.width*image.height)\n",
    "        for i in range(SP_NoiseNum):\n",
    "            randR=np.random.randint(0,image.width-1)\n",
    "            randG=np.random.randint(0,image.height-1)\n",
    "            randB=np.random.randint(0,3)\n",
    "            pim[randR,randG]=(0,0,0)\n",
    "        SP_NoiseImg.save(prefix + file.strip('.jpg') + '-Noise' + '.jpg')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ImageAugument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    " \n",
    "for i in tqdm(range(100)):\n",
    "  time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "img1 =  tensor([[[0.6078, 0.6196, 0.6157,  ..., 0.6314, 0.4667, 0.4431],\n",
      "         [0.6314, 0.6078, 0.6039,  ..., 0.6157, 0.5059, 0.4588],\n",
      "         [0.6431, 0.6196, 0.6118,  ..., 0.6118, 0.5176, 0.4863],\n",
      "         ...,\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333]],\n",
      "\n",
      "        [[0.6275, 0.6392, 0.6353,  ..., 0.6353, 0.4706, 0.4471],\n",
      "         [0.6510, 0.6275, 0.6235,  ..., 0.6196, 0.5098, 0.4627],\n",
      "         [0.6627, 0.6392, 0.6314,  ..., 0.6157, 0.5216, 0.4902],\n",
      "         ...,\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333]],\n",
      "\n",
      "        [[0.6039, 0.6157, 0.6118,  ..., 0.6118, 0.4471, 0.4235],\n",
      "         [0.6275, 0.6039, 0.6000,  ..., 0.5961, 0.4863, 0.4392],\n",
      "         [0.6392, 0.6157, 0.6078,  ..., 0.5922, 0.4980, 0.4667],\n",
      "         ...,\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333]]])\n",
      "img2 =  tensor([[[0.6039, 0.6157, 0.6118,  ..., 0.6118, 0.4471, 0.4235],\n",
      "         [0.6275, 0.6039, 0.6000,  ..., 0.5961, 0.4863, 0.4392],\n",
      "         [0.6392, 0.6157, 0.6078,  ..., 0.5922, 0.4980, 0.4667],\n",
      "         ...,\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333]],\n",
      "\n",
      "        [[0.6275, 0.6392, 0.6353,  ..., 0.6353, 0.4706, 0.4471],\n",
      "         [0.6510, 0.6275, 0.6235,  ..., 0.6196, 0.5098, 0.4627],\n",
      "         [0.6627, 0.6392, 0.6314,  ..., 0.6157, 0.5216, 0.4902],\n",
      "         ...,\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333]],\n",
      "\n",
      "        [[0.6078, 0.6196, 0.6157,  ..., 0.6314, 0.4667, 0.4431],\n",
      "         [0.6314, 0.6078, 0.6039,  ..., 0.6157, 0.5059, 0.4588],\n",
      "         [0.6431, 0.6196, 0.6118,  ..., 0.6118, 0.5176, 0.4863],\n",
      "         ...,\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333],\n",
      "         [0.7255, 0.7294, 0.7294,  ..., 0.7333, 0.7333, 0.7333]]])\n",
      "img_2 =  <PIL.Image.Image image mode=RGB size=400x397 at 0x24D232F50B8>\n"
     ]
    }
   ],
   "source": [
    "# https://zhuanlan.zhihu.com/p/27382990\n",
    "# PIL.Image/numpy.ndarray与Tensor的相互转换 \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "img_path = \"E:\\\\sc\\\\image_data\\\\meter\\\\meter_seg\\\\images\\\\test_true\\\\1.jpg\"\n",
    "\n",
    "# transforms.ToTensor()\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "##numpy.ndarray\n",
    "img = cv2.imread(img_path)# 读取图像\n",
    "# cv2.imshow('img', img)\n",
    "img1 = transform1(img) # 归一化到 [0.0,1.0]\n",
    "print(\"img1 = \",img1)\n",
    "# 转化为numpy.ndarray并显示\n",
    "img_1 = img1.numpy()*255\n",
    "img_1 = img_1.astype('uint8')\n",
    "img_1 = np.transpose(img_1, (1,2,0))\n",
    "cv2.imshow('img_1', img_1)\n",
    "cv2.waitKey()\n",
    "\n",
    "##PIL\n",
    "img = Image.open(img_path).convert('RGB') # 读取图像\n",
    "img2 = transform1(img) # 归一化到 [0.0,1.0]\n",
    "print(\"img2 = \",img2)\n",
    "#转化为PILImage并显示\n",
    "img_2 = transforms.ToPILImage()(img2).convert('RGB')\n",
    "print(\"img_2 = \",img_2)\n",
    "img_2.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image的缩放裁剪等操作\n",
    "# transforms.RandomCrop()\n",
    "transform4 = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomCrop((300,300)),\n",
    "    transforms.Resize((256, 256)), \n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img3 = transform4(img)\n",
    "img3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "img1 =  tensor([[[0.6275, 0.5922, 0.5804,  ..., 0.7647, 0.7647, 0.7725],\n         [0.6314, 0.6118, 0.5961,  ..., 0.7686, 0.7608, 0.7608],\n         [0.6353, 0.6235, 0.6039,  ..., 0.7569, 0.7569, 0.7529],\n         ...,\n         [0.7451, 0.7451, 0.7451,  ..., 0.7608, 0.7451, 0.7490],\n         [0.7451, 0.7451, 0.7451,  ..., 0.7490, 0.7529, 0.7529],\n         [0.7451, 0.7451, 0.7451,  ..., 0.7451, 0.7412, 0.7373]],\n\n        [[0.6549, 0.6314, 0.6275,  ..., 0.7647, 0.7647, 0.7725],\n         [0.6627, 0.6510, 0.6431,  ..., 0.7725, 0.7647, 0.7725],\n         [0.6627, 0.6588, 0.6510,  ..., 0.7725, 0.7686, 0.7725],\n         ...,\n         [0.7451, 0.7451, 0.7451,  ..., 0.7373, 0.7216, 0.7255],\n         [0.7451, 0.7451, 0.7451,  ..., 0.7294, 0.7294, 0.7333],\n         [0.7451, 0.7451, 0.7451,  ..., 0.7255, 0.7176, 0.7176]],\n\n        [[0.6510, 0.6275, 0.6235,  ..., 0.7647, 0.7647, 0.7725],\n         [0.6588, 0.6471, 0.6353,  ..., 0.7686, 0.7647, 0.7647],\n         [0.6588, 0.6549, 0.6431,  ..., 0.7608, 0.7608, 0.7569],\n         ...,\n         [0.7451, 0.7451, 0.7451,  ..., 0.7569, 0.7412, 0.7451],\n         [0.7451, 0.7451, 0.7451,  ..., 0.7490, 0.7490, 0.7451],\n         [0.7451, 0.7451, 0.7451,  ..., 0.7451, 0.7373, 0.7294]]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# https://www.aiuai.cn/aifarm1380.html\n",
    "# 2.基于 albumentations 的 pipline, opencv 版\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations import Compose, RandomCrop, Normalize, HorizontalFlip, Resize, ShiftScaleRotate\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "img_path = \"E:\\\\sc\\\\image_data\\\\meter\\\\meter_seg\\\\images\\\\test_true\\\\1.jpg\"\n",
    "\n",
    "albumentations_transform = Compose([\n",
    "    Resize(256, 256), \n",
    "    RandomCrop(224, 224),\n",
    "    HorizontalFlip(),\n",
    "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n",
    "    # Normalize(\n",
    "    #     mean=[0.485, 0.456, 0.406],\n",
    "    #     std=[0.229, 0.224, 0.225],\n",
    "    # ),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "img = cv2.imread(img_path)# 读取图像\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "augmented = albumentations_transform(image=img)\n",
    "img4 = augmented['image']\n",
    "print(\"img1 = \",img4)\n",
    "# 转化为numpy.ndarray并显示\n",
    "img_4 = img4.numpy()*255\n",
    "img_4 = img_4.astype('uint8')\n",
    "img_4 = np.transpose(img_4, (1,2,0))\n",
    "cv2.imshow('img_4', img_4)\n",
    "cv2.waitKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}